/****************************************************************************************
 * AGENT + TOOL SETUP WITH USER CONTEXT + STRUCTURED OUTPUT
 * --------------------------------------------------------------------------------------
 * This example demonstrates a PRODUCTION-READY agent pattern with:
 *
 * 1Ô∏è‚É£ Runtime context (user identity comes from config, not prompts)
 * 2Ô∏è‚É£ Tool chaining via ReAct (location ‚Üí weather)
 * 3Ô∏è‚É£ Structured output using `responseFormat`
 *
 * KEY IDEA:
 * - The agent DOES NOT return free-form text
 * - It MUST return a JSON object matching a schema
 * - This makes agents safe to consume in APIs, UIs, and workflows
 ****************************************************************************************/

import { ChatOpenAI } from "@langchain/openai";
import "dotenv/config";
import { tool } from "@langchain/core/tools";
import { z } from "zod";
import { createAgent } from "langchain";

/****************************************************************************************
 * SYSTEM PROMPT (POLICY + STRATEGY ONLY)
 * --------------------------------------------------------------------------------------
 * The system prompt defines:
 * - Role
 * - Tool usage strategy
 * - High-level behavior
 *
 * IMPORTANT:
 * ‚ùå No user_id
 * ‚ùå No database logic
 * ‚ùå No response formatting rules
 *
 * WHY?
 * - Prompts are for reasoning policy
 * - Data + formatting are enforced elsewhere
 ****************************************************************************************/
const systemPrompt = `
You are an expert weather assistant who responds in a humorous way.

You have access to 2 tools:
- get_user_location
- get_weather

Behavior rules:
1. If the user asks about weather, ensure the location is known.
2. If location is implied ("outside", "where I am"), call get_user_location.
3. Then call get_weather.
4. Do not ask the user for their location.
`;

/****************************************************************************************
 * TOOL 1: get_user_location (CONTEXT-DRIVEN TOOL)
 * --------------------------------------------------------------------------------------
 * This tool:
 * - Takes NO input from the LLM
 * - Reads trusted data from runtime config
 *
 * Pattern:
 * (_, config)  ‚Üí ignore LLM args, use backend context instead
 ****************************************************************************************/
const getUserLocation = tool(
  (_, config) => {
    const userId = config.context.user_id;

    // Demo logic ‚Äî replace with DB / user service in production
    return userId === "1" ? "New York" : "San Francisco";
  },
  {
    name: "get_user_location",
    description: "Resolve the user's current location using backend context",
    schema: z.object({}), // ‚¨ÖÔ∏è No LLM arguments allowed
  }
);

/****************************************************************************************
 * TOOL 2: get_weather (LLM-INPUT-DRIVEN TOOL)
 * --------------------------------------------------------------------------------------
 * This tool:
 * - Receives structured input generated by the LLM
 * - Is validated by Zod before execution
 ****************************************************************************************/
const getWeather = tool(
  ({ city }: { city: string }) => {
    return `It's always sunny in ${city}`;
  },
  {
    name: "get_weather",
    description: "Retrieve the weather for a given city",
    schema: z.object({
      city: z.string(),
    }),
  }
);

/****************************************************************************************
 * RUNTIME CONFIGURATION
 * --------------------------------------------------------------------------------------
 * Runtime config is injected at invocation time.
 *
 * KEY PRINCIPLE:
 * - Agents NEVER infer identity from prompts
 * - Identity comes from trusted runtime config
 ****************************************************************************************/
const config = {
  context: {
    user_id: "1", // Authenticated user
  },
};

/****************************************************************************************
 * MODEL CONFIGURATION (OpenRouter ‚Äì Free Tier)
 ****************************************************************************************/
const llm = new ChatOpenAI({
  model: "mistralai/devstral-2512:free",
  apiKey: process.env.OPENROUTER_API_KEY!,
  configuration: {
    baseURL: "https://openrouter.ai/api/v1",
  },
});

/****************************************************************************************
 * STRUCTURED RESPONSE FORMAT (CRITICAL FOR PRODUCTION)
 * --------------------------------------------------------------------------------------
 * This schema defines the ONLY valid final output.
 *
 * The agent MUST return JSON that matches this structure.
 * No extra text. No explanations. No tool traces.
 *
 * WHY THIS MATTERS:
 * ‚úÖ Safe API consumption
 * ‚úÖ No string parsing
 * ‚úÖ No hallucinated fields
 * ‚úÖ Works with free + paid models
 ****************************************************************************************/
const responseFormat = z.object({
  humour_response: z.string(),
  weather_conditions: z.string(),
});

/****************************************************************************************
 * AGENT CREATION
 * --------------------------------------------------------------------------------------
 * createAgent automatically:
 * - Builds the ReAct loop
 * - Injects tools into the prompt
 * - Enforces structured output
 * - Stops execution when schema is satisfied
 ****************************************************************************************/
const agent = createAgent({
  model: llm,
  tools: [getUserLocation, getWeather],
  systemPrompt,
  responseFormat, // ‚¨ÖÔ∏è Enforces final output shape
});

/****************************************************************************************
 * AGENT INVOCATION
 * --------------------------------------------------------------------------------------
 * Flow:
 * 1Ô∏è‚É£ User message arrives
 * 2Ô∏è‚É£ Agent reasons ‚Üí needs location
 * 3Ô∏è‚É£ Calls get_user_location (_, config)
 * 4Ô∏è‚É£ Calls get_weather({ city })
 * 5Ô∏è‚É£ Produces FINAL JSON matching responseFormat
 ****************************************************************************************/
const response = await agent.invoke(
  {
    messages: [
      {
        role: "user",
        content: "What is the weather outside?",
      },
    ],
  },
  config
);

/****************************************************************************************
 * CONSUMING THE RESULT (THIS IS THE PAYOFF)
 * --------------------------------------------------------------------------------------
 * Instead of parsing strings, we get a typed object:
 *
 * response.structuredResponse = {
 *   humour_response: "...",
 *   weather_conditions: "..."
 * }
 *
 * This is what makes agents usable in real systems.
 ****************************************************************************************/
console.log("ü§ñ STRUCTURED RESPONSE:");
console.log(response.structuredResponse);

/*
Example output:

{
  humour_response: "Looks like the sun clocked in early today üòÑ",
  weather_conditions: "It's always sunny in New York"
}
*/
